# -*- coding: utf-8 -*-
"""ML.ipynb

Automatically generated by Colab.

"""

# Cell 1:libraries
!pip install -q scikit-learn pandas numpy joblib
print("Packages installed")

# Cell 2: imports, random seed, helper
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import joblib
import json
from IPython.display import display

np.random.seed(42)

def show_df(df, n=5):
    display(df.head(n))

# Cell 3: create synthetic data with dispatch features
n = 3000  # number of synthetic records

# Generate fault count (0-12 faults per day is realistic)
faults_today = np.random.poisson(lam=3, size=n)  # Average 3 faults per day

df = pd.DataFrame({
    'distance_m': np.random.exponential(scale=2000, size=n),      # distance to fault (meters)
    'past_perf': np.clip(np.random.normal(7, 1.5, n), 1, 10),     # team past performance (1-10)
    'fault_history': np.random.poisson(1.0, n),                   # similar faults handled (count)
    'fatigue_h': np.clip(faults_today * 2, 0, 24),               # crew fatigue (hours) - converted from fault count
    'fault_severity': np.random.choice([1, 2, 3], size=n)         # 1=low,2=medium,3=high
})

def dist_cat(m):
    if m < 1000: return 0
    if m < 5000: return 1
    return 2

df['distance_cat'] = df['distance_m'].apply(dist_cat)

print("Number of synthetic records:", len(df))
print("Sample synthetic dispatch data:")
show_df(df, n=20)

# Cell 4: rule-based dispatch score and ML model training

# rule-based scores (0..1 for each factor)
dist_score = 1 - df['distance_m'] / (df['distance_m'].max() + 1e-6)
dist_score = dist_score.clip(0, 1)

fh_score = df['fault_history'] / (df['fault_history'].max() + 1e-6)
fh_score = fh_score.clip(0, 1)

fatigue_score = 1 - (df['fatigue_h'] / 24.0)
fatigue_score = fatigue_score.clip(0, 1)

severity_score = df['fault_severity'] / 3.0      # 1/3, 2/3, 1
perf_score = df['past_perf'] / 10.0              # 0..1

# weighted rule-based dispatch score
# Redistributed weights after removing traffic (20% removed)
# New weights: distance=0.45, fault_history=0.25, fatigue=0.15, severity=0.05, perf=0.10
rule_score = (
    0.45 * dist_score +      # Increased from 0.4
    0.25 * fh_score +         # Increased from 0.2
    0.15 * fatigue_score +   # Increased from 0.1
    0.05 * severity_score +  # Keep same
    0.10 * perf_score         # Increased from 0.05
)

df['dispatch_score'] = (rule_score - rule_score.min()) / (rule_score.max() - rule_score.min()) * 100

print("Sample with dispatch_score:")
show_df(df[['distance_m','distance_cat','past_perf','fault_history','fatigue_h',
            'fault_severity','dispatch_score']], n=20)

# ML model to learn dispatch_score
X = df[['distance_m','distance_cat','past_perf','fault_history',
        'fatigue_h','fault_severity']]
y = df['dispatch_score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

ml_model = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)
ml_model.fit(X_train, y_train)
preds = ml_model.predict(X_test)

print("Dispatch ML MAE:", round(mean_absolute_error(y_test, preds), 3))
print("Dispatch ML R2:", round(r2_score(y_test, preds), 3))

joblib.dump({'model': ml_model, 'features': X.columns.tolist()}, 'dispatch_ml_model.pkl')
print("\nSaved model: dispatch_ml_model.pkl")

# Cell 5: use ML model to pick best vehicle

artifact = joblib.load('dispatch_ml_model.pkl')
dispatch_model = artifact['model']
dispatch_features = artifact['features']

def ai_dispatch_decision(candidates, model, feature_names):
    rows = []
    for c in candidates:
        rows.append([c[f] for f in feature_names])
    df_cand = pd.DataFrame(rows, columns=feature_names)
    scores = model.predict(df_cand)
    df_cand['predicted_dispatch_score'] = scores
    best_idx = int(df_cand['predicted_dispatch_score'].idxmax())
    return best_idx, df_cand

def extract_features_from_system_data(vehicle_data, fault_data, distance_m):
    """
    Helper function to extract ML features from system data structures.
    This function shows the expected format for microservice integration.
    
    Args:
        vehicle_data: Dict with keys:
            - performance_ratio: float (0-1)
            - fault_history_count: int (count of similar fault_type)
            - fatigue_count: int (faults today)
        fault_data: Dict with keys:
            - category: str ("High", "Medium", "Low")
        distance_m: float (distance in meters from routing service)
    
    Returns:
        Dict with ML model features
    """
    # Calculate distance category
    if distance_m < 1000:
        distance_cat = 0
    elif distance_m < 5000:
        distance_cat = 1
    else:
        distance_cat = 2
    
    # Convert performance ratio (0-1) to scale (1-10)
    past_perf = vehicle_data['performance_ratio'] * 10
    
    # Use fault history count directly
    fault_history = vehicle_data['fault_history_count']
    
    # Convert fatigue count to hours (2 hours per fault, max 24)
    fatigue_h = min(vehicle_data['fatigue_count'] * 2, 24)
    
    # Map category to severity
    category_map = {"High": 3, "Medium": 2, "Low": 1}
    fault_severity = category_map.get(fault_data['category'], 2)  # Default to Medium
    
    return {
        'distance_m': distance_m,
        'distance_cat': distance_cat,
        'past_perf': past_perf,
        'fault_history': fault_history,
        'fatigue_h': fatigue_h,
        'fault_severity': fault_severity
    }

# Example usage:
example_vehicle = {
    'performance_ratio': 0.75,
    'fault_history_count': 2,
    'fatigue_count': 3
}
example_fault = {
    'category': 'High'
}
example_distance = 1250.5

features = extract_features_from_system_data(example_vehicle, example_fault, example_distance)
print("\nExample feature extraction:")
print(json.dumps(features, indent=2))

# example: 3 vehicle options
candidates = [
    {
        'distance_m': 800,
        'distance_cat': 0,
        'past_perf': 7.5,
        'fault_history': 1,
        'fatigue_h': 5,
        'fault_severity': 3
    },
    {
        'distance_m': 2500,
        'distance_cat': 1,
        'past_perf': 9.0,
        'fault_history': 3,
        'fatigue_h': 3,
        'fault_severity': 3
    },
    {
        'distance_m': 6000,
        'distance_cat': 2,
        'past_perf': 6.5,
        'fault_history': 0,
        'fatigue_h': 2,
        'fault_severity': 2
    }
]

best_idx, cand_df = ai_dispatch_decision(candidates, dispatch_model, dispatch_features)
print("Candidates with predicted dispatch scores:")
print(cand_df)
print("\nBest vehicle index to dispatch:", best_idx)
print("Best vehicle data:", candidates[best_idx])

print("\nExample JSON payload for one vehicle candidate:")
print(json.dumps(candidates[0], indent=2))

# ============================================================================
# INTEGRATION NOTES: Feature Extraction from Node.js System
# ============================================================================
"""
This section documents how to extract features from the Node.js dispatch system
for use with this ML model in a microservice.

FEATURE MAPPING:
----------------
1. distance_m (float):
   - Source: routingService.calculateRoute(vehicleGPS, faultGPS)
   - Extract: route.distance (already in meters)
   - Example: route = await calculateRoute({lat: 24.86, lng: 67.00}, {lat: 24.90, lng: 67.05})
              distance_m = route.distance

2. distance_cat (int: 0, 1, or 2):
   - Source: Derived from distance_m
   - Logic: 0 if distance_m < 1000, 1 if < 5000, else 2
   - Example: distance_cat = 0 if distance_m < 1000 else (1 if distance_m < 5000 else 2)

3. past_perf (float: 1-10):
   - Source: calculatePerformanceScoresBatch() returns 0-1 ratio
   - Convert: past_perf = performanceRatio * 10
   - Example: If performanceRatio = 0.75, then past_perf = 7.5

4. fault_history (int: count):
   - Source: checkFaultTypeExperienceBatch(vehicleIds, faultType)
   - Extract: Count of resolved faults with same fault_type
   - Example: experienceMap.get(vehicleId) returns count (not boolean)
   - Note: Current system returns boolean, but count is available in aggregation

5. fatigue_h (float: 0-24):
   - Source: calculateFatigueLevelsBatch() returns count of faults today
   - Convert: fatigue_h = min(faultsToday * 2, 24)  # 2 hours per fault
   - Example: If faultsToday = 3, then fatigue_h = 6

6. fault_severity (int: 1, 2, or 3):
   - Source: fault.category ("High", "Medium", "Low")
   - Map: "High" → 3, "Medium" → 2, "Low" → 1
   - Example: fault_severity = 3 if category === "High"

EXAMPLE JSON PAYLOAD FOR MICROSERVICE:
---------------------------------------
POST /api/ml/dispatch/predict
{
  "candidates": [
    {
      "distance_m": 1250.5,
      "distance_cat": 1,
      "past_perf": 8.2,
      "fault_history": 2,
      "fatigue_h": 4.0,
      "fault_severity": 3
    },
    {
      "distance_m": 3500.0,
      "distance_cat": 1,
      "past_perf": 6.5,
      "fault_history": 0,
      "fatigue_h": 8.0,
      "fault_severity": 3
    }
  ]
}

RESPONSE:
---------
{
  "best_index": 0,
  "scores": [85.3, 72.1],
  "predictions": [
    {"index": 0, "score": 85.3},
    {"index": 1, "score": 72.1}
  ]
}

LATENCY EXPECTATIONS:
----------------------
- Model loading: ~100-200ms (one-time, on service start)
- Single prediction: ~5-20ms
- Batch prediction (10 candidates): ~10-50ms
- Total API call (with feature extraction): <100ms target
"""

print("\n" + "="*70)
print("INTEGRATION READY")
print("="*70)
print("Model trained with 6 features (traffic removed)")
print("Features: distance_m, distance_cat, past_perf, fault_history, fatigue_h, fault_severity")
print("Model file: dispatch_ml_model.pkl")
print("Ready for microservice deployment")
print("="*70)